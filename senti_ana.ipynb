{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JASONZ777/4D_radar_simulator_PointNet/blob/main/senti_ana.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9p4kUCHeYZp"
      },
      "source": [
        "## Design a hard prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOAwEbKveYZr"
      },
      "source": [
        "# Method 1: Prompt-BERT (add a classification layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-wEtjkOeYZr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP2jHdg9eYZs"
      },
      "outputs": [],
      "source": [
        "# define a hard prompt, and its ID\n",
        "def get_prompt(x):\n",
        "    prompt = f'总体上来说很[MASK]: {x}'\n",
        "    return {\n",
        "        'prompt': prompt,\n",
        "        'mask_id': prompt.find('[MASK]') # since only one [MASK], find the ID\n",
        "    }\n",
        "\n",
        "# map the label to the word in the dictionary\n",
        "# (tokenizer, words with similiar meanings have similar embeddings, that's why we could calculate the loss)\n",
        "def map_label(tokenizer):\n",
        "    return {\n",
        "        '1': {'token': '好', 'id': tokenizer.convert_tokens_to_ids(\"好\")},\n",
        "        '0': {'token': '差', 'id': tokenizer.convert_tokens_to_ids(\"差\")}\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXEWZwRBeYZs",
        "outputId": "867d108f-dd1c-46a2-b2fb-60e091b7a9fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "verbalizer: {'1': {'token': '好', 'id': 1962}, '0': {'token': '差', 'id': 2345}}\n",
            "prompt: 总体上来说很[MASK]: 这个宾馆比较陈旧了，特价的房间也很一般。\n",
            "prompt tokens: ['[CLS]', '总', '体', '上', '来', '说', '很', '[MASK]', ':', '这', '个', '宾', '馆', '比', '较', '陈', '旧', '了', '，', '特', '价', '的', '房', '间', '也', '很', '一', '般', '。', '[SEP]']\n",
            "mask idx: 7\n"
          ]
        }
      ],
      "source": [
        "# a testing from Huggingface\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"bert-base-chinese\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "comment = '这个宾馆比较陈旧了，特价的房间也很一般。'\n",
        "\n",
        "print('verbalizer:', map_label(tokenizer))\n",
        "\n",
        "prompt_data = get_prompt(comment)\n",
        "prompt, mask_offset = prompt_data['prompt'], prompt_data['mask_id']\n",
        "\n",
        "encoding = tokenizer(prompt, truncation=True)\n",
        "tokens = encoding.tokens()\n",
        "mask_idx = encoding.char_to_token(mask_offset)\n",
        "\n",
        "print('prompt:', prompt)\n",
        "print('prompt tokens:', tokens)\n",
        "print('mask idx:', mask_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWF5aCp7eYZt"
      },
      "source": [
        "## Upload dataset combined with prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp5COznYeYZt"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class upload_dataset(Dataset):\n",
        "    def __init__(self, data_file):\n",
        "        self.data = self.load_data(data_file)\n",
        "\n",
        "    def load_data(self, data_file):\n",
        "        Data = {}\n",
        "        with open(data_file, 'rt', encoding='utf-8') as f:\n",
        "            for idx, line in enumerate(f):\n",
        "                items = line.strip().split('\\t')\n",
        "                prompts = get_prompt(items[0])\n",
        "                assert len(items) == 2\n",
        "                Data[idx] = {\n",
        "                    'comment': items[0],\n",
        "                    'label': int(items[1]),\n",
        "                    'prompt': prompts['prompt'],\n",
        "                    'mask_id': prompts['mask_id']\n",
        "                }\n",
        "        return Data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "No2fI35DeYZt",
        "outputId": "323d36c2-081d-4a9f-a59a-44de6ec0e06c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train set size: 9600\n",
            "valid set size: 1200\n",
            "test set size: 1200\n",
            "{'comment': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'label': 1, 'prompt': '总体上来说很[MASK]: 选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'mask_id': 6}\n"
          ]
        }
      ],
      "source": [
        "# testing\n",
        "train_data = upload_dataset('chnsenticorp/train/part.0')\n",
        "valid_data = upload_dataset('chnsenticorp/dev/part.0')\n",
        "test_data = upload_dataset('chnsenticorp/test/part.0')\n",
        "print(f'train set size: {len(train_data)}')\n",
        "print(f'valid set size: {len(valid_data)}')\n",
        "print(f'test set size: {len(test_data)}')\n",
        "print(next(iter(train_data)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3VL6E4zeYZu"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcObnKk3eYZu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "checkpoint = 'bert-base-chinese'\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "# find the id of the label defined in tokenizer\n",
        "label = map_label(tokenizer)\n",
        "pos_id, neg_id = label['1']['id'], label['0']['id']\n",
        "# Dataloader, in NLP we usually use collate_fn to do the padding to make sure samples have the same sequence length\n",
        "def collate(batch_samples): # operate on each batch\n",
        "    batch_sentence = []\n",
        "    batch_label = []\n",
        "    batch_mask_id = []\n",
        "    max_length = 0\n",
        "    for sample in batch_samples:\n",
        "        batch_sentence.append(sample['prompt'])\n",
        "        encoding = tokenizer(sample['prompt'], truncation=True)\n",
        "        max_length = max(max_length, len(encoding.tokens())) # dynamic padding to the longest\n",
        "        mask_idx = encoding.char_to_token(sample['mask_id']) # convert the character id of mask in prompts to token id in tokenized sentence\n",
        "        batch_mask_id.append(mask_idx) # if pre-fix prompt, mask id will be the same\n",
        "        batch_label.append(sample['label'])\n",
        "    batch_inputs = tokenizer(batch_sentence, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "    label_id = [neg_id, pos_id]\n",
        "    return {\n",
        "        'batch_inputs':batch_inputs,\n",
        "        'batch_mask_id': batch_mask_id,\n",
        "        'label_id': label_id,\n",
        "        'labels': batch_label\n",
        "\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFP86aikeYZu"
      },
      "outputs": [],
      "source": [
        "# a testing for dataloader\n",
        "# batch_data = next(iter(train_loader))\n",
        "# print('batch_X shape:', {k: v.shape for k, v in batch_data['batch_inputs'].items()})\n",
        "# print(batch_data['batch_inputs'])\n",
        "# print(batch_data['batch_mask_id'])\n",
        "# print(batch_data['label_id'])\n",
        "# print(batch_data['labels'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcYMnkxReYZu"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGoGX-fxeYZu"
      },
      "source": [
        "Look into the structure of the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REHcXNIeeYZu",
        "outputId": "cd6bb0ea-b1ff-47cb-aec4-65833997983c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n",
            "21128\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForMaskedLM, BertModel # the difference is that the former class contains a head layer for specific MLM task;\n",
        "# BertModel is the base class, and we need to define the head layer e.g. the softmax\n",
        "\n",
        "checkpoint = 'bert-base-chinese'\n",
        "pre_trained_model = BertModel.from_pretrained(checkpoint)\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "vocab_size = len(tokenizer)\n",
        "print(pre_trained_model)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqsGVYYQeYZu"
      },
      "source": [
        "Frozen all the parameters + Add the classiifcation layer (trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgCcKn0YeYZu"
      },
      "outputs": [],
      "source": [
        "for param in pre_trained_model.parameters():\n",
        "    param.requires_grad_(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUJZ4c8leYZv"
      },
      "outputs": [],
      "source": [
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, model):\n",
        "        super().__init__()\n",
        "        self.fc = torch.nn.Linear(768, vocab_size)\n",
        "        self.md = model\n",
        "\n",
        "    def forward(self, batch_inputs, batch_mask_id, label_id, labels=None):\n",
        "        input_data = batch_inputs\n",
        "        with torch.no_grad():\n",
        "            out = self.md(**input_data)\n",
        "\n",
        "        out = self.fc(out.last_hidden_state[:, batch_mask_id[0]]) # only works when the masking position is fixed (batch, vocab_size)\n",
        "        out = out[:,label_id] # we only want to explore the prediction on the label_id\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69krPIXBeYZv",
        "outputId": "5e3204ac-40eb-4d09-a8eb-3e7f816b7290"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "# Hyper-parameters\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Model(vocab_size, pre_trained_model)\n",
        "model.to(device)\n",
        "\n",
        "# put data to GPU\n",
        "def to_device(batch_data):\n",
        "    new_batch_data = {}\n",
        "    for k, v in batch_data.items():\n",
        "        if k == 'batch_inputs':\n",
        "            new_batch_data[k] = {\n",
        "                k_: v_.to(device) for k_, v_ in v.items()\n",
        "            }\n",
        "        elif k == 'label_id':\n",
        "            new_batch_data[k] = v\n",
        "        else:\n",
        "            new_batch_data[k] = torch.tensor(v).to(device)\n",
        "    return new_batch_data\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=4e-5)\n",
        "loss_fun = torch.nn.CrossEntropyLoss()\n",
        "num_epoch = 10\n",
        "batch_size = 32\n",
        "\n",
        "# encapsulate into the dataloader as input\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
        "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
        "\n",
        "# logs\n",
        "loss_hists = {'train':[],'val': []}\n",
        "acc_hists = {'train':[],'val': []}\n",
        "# batch_data = next(iter(train_loader))\n",
        "# batch_data = to_device(batch_data)\n",
        "# outputs = model(**batch_data)\n",
        "# print(outputs.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAVPF2w0eYZv",
        "outputId": "91a076aa-419b-4d7c-ae93-83d0baa59d01"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 300/300 [02:51<00:00,  1.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Training Loss: 0.5979, Training accuracy: 0.7475\n",
            "Epoch 1/10, Validation loss: 0.5026, Validation accuracy: 0.8273\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 300/300 [03:07<00:00,  1.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10, Training Loss: 0.4896, Training accuracy: 0.8210\n",
            "Epoch 2/10, Validation loss: 0.4285, Validation accuracy: 0.8331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 300/300 [03:14<00:00,  1.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10, Training Loss: 0.4415, Training accuracy: 0.8275\n",
            "Epoch 3/10, Validation loss: 0.3924, Validation accuracy: 0.8413\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 300/300 [03:15<00:00,  1.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10, Training Loss: 0.4139, Training accuracy: 0.8361\n",
            "Epoch 4/10, Validation loss: 0.3781, Validation accuracy: 0.8438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 300/300 [03:11<00:00,  1.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10, Training Loss: 0.4000, Training accuracy: 0.8364\n",
            "Epoch 5/10, Validation loss: 0.3673, Validation accuracy: 0.8446\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 300/300 [03:13<00:00,  1.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10, Training Loss: 0.3874, Training accuracy: 0.8425\n",
            "Epoch 6/10, Validation loss: 0.3590, Validation accuracy: 0.8454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 300/300 [03:16<00:00,  1.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10, Training Loss: 0.3796, Training accuracy: 0.8460\n",
            "Epoch 7/10, Validation loss: 0.3482, Validation accuracy: 0.8438\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 300/300 [03:13<00:00,  1.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10, Training Loss: 0.3776, Training accuracy: 0.8441\n",
            "Epoch 8/10, Validation loss: 0.3525, Validation accuracy: 0.8470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 300/300 [03:18<00:00,  1.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10, Training Loss: 0.3680, Training accuracy: 0.8518\n",
            "Epoch 9/10, Validation loss: 0.3443, Validation accuracy: 0.8454\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 300/300 [03:18<00:00,  1.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10, Training Loss: 0.3640, Training accuracy: 0.8511\n",
            "Epoch 10/10, Validation loss: 0.3378, Validation accuracy: 0.8495\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "for epoch in range(num_epoch):\n",
        "    train_loss = 0\n",
        "    i = 1\n",
        "    correct_num = 0\n",
        "    for batch_data in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epoch}\"):\n",
        "        model.train() # training mode\n",
        "        batch_data = to_device(batch_data)\n",
        "        output = model(**batch_data)\n",
        "        loss = loss_fun(output, batch_data['labels'])\n",
        "        loss.backward()\n",
        "        train_loss+=loss.item()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()# set gradient to 0 when batch is updated\n",
        "\n",
        "\n",
        "        # if i % 10 == 0: # record every 10 training batches\n",
        "        #     output = output.argmax(dim=1)\n",
        "        #     acc = (output == batch_data['labels']).sum().item()/ len(batch_data['labels'])\n",
        "        #     print(f'Training stage:Batch {i}, Loss: {loss.item()}, Accuracy: {acc}')\n",
        "\n",
        "        # if i % 30 == 0: # validate every 30 batches\n",
        "        #     model.eval()\n",
        "        #     batch_val = next(iter(valid_loader))\n",
        "        #     with torch.no_grad():\n",
        "        #         batch_val = to_device(batch_val)\n",
        "        #         output = model(**batch_val)\n",
        "        #     val_loss = loss_fun(output, torch.tensor(batch_val['labels']))\n",
        "        #     output = output.argmax(dim=1)\n",
        "        #     acc = (output == torch.tensor(batch_val['labels'])).sum().item()/ len(batch_val['labels'])\n",
        "        #     print(f'Validation stage:Batch {i}, Loss: {loss.item()}, Accuracy: {acc}')\n",
        "\n",
        "        # i+=1\n",
        "        output = output.argmax(dim=1)\n",
        "        correct_num += (output == batch_data['labels']).sum().item()\n",
        "\n",
        "    acc = correct_num/ (len(train_loader)*batch_size)\n",
        "    average_loss = train_loss/len(train_loader)\n",
        "    loss_hists['train'].append(average_loss)\n",
        "    acc_hists['train'].append(acc)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epoch}, Training Loss: {average_loss:.4f}, Training accuracy: {acc:.4f}\")\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0\n",
        "        correct_num = 0\n",
        "        for i, batch_data in enumerate(valid_loader):\n",
        "            batch_data = to_device(batch_data)\n",
        "            output = model(**batch_data)\n",
        "            loss = loss_fun(output, batch_data['labels'])\n",
        "            output = output.argmax(dim=1)\n",
        "\n",
        "            correct_num += (output == batch_data['labels']).sum().item()\n",
        "            val_loss+=loss\n",
        "\n",
        "        acc = correct_num/ (len(valid_loader)*batch_size)\n",
        "        average_val_loss = val_loss/len(valid_loader)\n",
        "\n",
        "        loss_hists['val'].append(average_val_loss)\n",
        "        acc_hists['val'].append(acc)\n",
        "        print(f'Epoch {epoch + 1}/{num_epoch}, Validation loss: {average_val_loss:.4f}, Validation accuracy: {acc:.4f}')\n",
        "\n",
        "\n",
        "torch.save(model.state_dict(), 'model_parameters.pth')\n",
        "torch.save(model, 'model_file.pth')\n",
        "\n",
        "# draw the loss figures\n",
        "fig, ax = plt.subplots(1,2)\n",
        "ax[0].plot(torch.tensor(loss_hists['train']).cpu().detach().numpy()) # can only matplotlib to plot numpy on CPU\n",
        "ax[0].plot(torch.tensor(loss_hists['val']).cpu().detach().numpy())\n",
        "ax[0].set_title('Loss-Epoch')\n",
        "ax[0].set_xlabel('Epoch')\n",
        "ax[0].set_ylabel('Loss')\n",
        "ax[0].legend(['Training loss', 'Validation loss'])\n",
        "\n",
        "ax[1].plot(torch.tensor(acc_hists['train']).cpu().detach().numpy())\n",
        "ax[1].plot(torch.tensor(acc_hists['val']).cpu().detach().numpy())\n",
        "ax[1].set_title('Acc-Epoch')\n",
        "ax[1].set_xlabel('Epoch')\n",
        "ax[1].set_ylabel('Accuracy')\n",
        "ax[1].legend(['Training acc', 'Validation acc'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf2saALneYZv"
      },
      "source": [
        "# Method 2: LoRA fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euGeuurzeYZv",
        "outputId": "55ce3a39-2373-4e3f-eb6d-f8a81ed188e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (0.27.2)\n",
            "Requirement already satisfied: loralib in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (0.1.2)\n",
            "Requirement already satisfied: peft in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (0.8.2)\n",
            "Requirement already satisfied: huggingface-hub in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from accelerate) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from accelerate) (1.24.2)\n",
            "Requirement already satisfied: psutil in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from accelerate) (5.9.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in c:\\users\\jasonz7\\appdata\\roaming\\python\\python39\\site-packages (from accelerate) (1.13.1+cu116)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: transformers in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from peft) (4.38.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from peft) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from huggingface-hub->accelerate) (4.9.0)\n",
            "Requirement already satisfied: requests in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from huggingface-hub->accelerate) (2.28.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from huggingface-hub->accelerate) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from huggingface-hub->accelerate) (2023.10.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from tqdm->peft) (0.4.6)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from transformers->peft) (0.15.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jasonz7\\.conda\\envs\\pytorch\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.4)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jasonz7\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jasonz7\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jasonz7\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jasonz7\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jasonz7\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\jasonz7\\appdata\\roaming\\python\\python39\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate loralib peft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOChyQa9eYZv",
        "outputId": "a9ba79a1-af5c-4ce5-96cf-d694274220a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN9ZbSKaeYZv",
        "outputId": "e0e32aad-dea8-4393-f0ac-ba1aacbf5423"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "c:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:167: UserWarning: Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            "\n",
            "  warn(msg)\n",
            "c:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:167: UserWarning: C:\\Users\\JASONZ7\\.conda\\envs\\pytorch did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n",
            "\n",
            "===================================BUG REPORT===================================\n",
            "================================================================================\n",
            "The following directories listed in your path were found to be non-existent: {WindowsPath('C'), WindowsPath('/Users/JASONZ7/.conda/envs/pytorch/lib')}\n",
            "The following directories listed in your path were found to be non-existent: {WindowsPath('vs/workbench/api/node/extensionHostProcess')}\n",
            "The following directories listed in your path were found to be non-existent: {WindowsPath('/matplotlib_inline.backend_inline'), WindowsPath('module')}\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "The following directories listed in your path were found to be non-existent: {WindowsPath('/usr/local/cuda/lib64')}\n",
            "DEBUG: Possible options found for libcudart.so: set()\n",
            "CUDA SETUP: PyTorch settings found: CUDA_VERSION=116, Highest Compute Capability: 8.6.\n",
            "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
            "CUDA SETUP: Required library version not found: libbitsandbytes_cuda116.so. Maybe you need to compile it from source?\n",
            "CUDA SETUP: Defaulting to libbitsandbytes_cpu.so...\n",
            "\n",
            "================================================ERROR=====================================\n",
            "CUDA SETUP: CUDA detection failed! Possible reasons:\n",
            "1. You need to manually override the PyTorch CUDA version. Please see: \"https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
            "2. CUDA driver not installed\n",
            "3. CUDA not installed\n",
            "4. You have multiple conflicting CUDA libraries\n",
            "5. Required library not pre-compiled for this bitsandbytes release!\n",
            "CUDA SETUP: If you compiled from source, try again with `make CUDA_VERSION=DETECTED_CUDA_VERSION` for example, `make CUDA_VERSION=113`.\n",
            "CUDA SETUP: The CUDA version for the compile might depend on your conda install. Inspect CUDA version via `conda list | grep cuda`.\n",
            "================================================================================\n",
            "\n",
            "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
            "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
            "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
            "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
            "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
            "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
            "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://raw.githubusercontent.com/TimDettmers/bitsandbytes/main/cuda_install.sh\n",
            "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
            "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n",
            "CUDA SETUP: Setup Failed!\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):\n\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\utils\\import_utils.py:1390\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1389\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:11\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bitsandbytes_available():\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\bitsandbytes\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     MatmulLtState,\n\u001b[0;32m      9\u001b[0m     bmm_cublas,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     matmul_4bit\n\u001b[0;32m     14\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\bitsandbytes\\research\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     switchback_bnb,\n\u001b[0;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[0;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[0;32m      6\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\bitsandbytes\\research\\nn\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\bitsandbytes\\research\\nn\\modules.py:8\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalOptimManager\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\bitsandbytes\\optim\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madagrad\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\bitsandbytes\\cextension.py:20\u001b[0m\n\u001b[0;32m     19\u001b[0m     CUDASetup\u001b[38;5;241m.\u001b[39mget_instance()\u001b[38;5;241m.\u001b[39mprint_log_stack()\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001b[39m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;124m    python -m bitsandbytes\u001b[39m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[38;5;124m'''\u001b[39m)\n\u001b[0;32m     28\u001b[0m lib\u001b[38;5;241m.\u001b[39mcadam32bit_grad_fp32 \u001b[38;5;66;03m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      2\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-chinese\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(\n\u001b[0;32m      5\u001b[0m     load_in_4bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m     bnb_4bit_use_double_quant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      7\u001b[0m     bnb_4bit_quant_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnf4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m     bnb_4bit_compute_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mbfloat16\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForMaskedLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:561\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    560\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 561\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    562\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    563\u001b[0m     )\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    566\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    567\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\modeling_utils.py:3389\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3386\u001b[0m     keep_in_fp32_modules \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3389\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\n\u001b[0;32m   3391\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3393\u001b[0m     \u001b[38;5;66;03m# We store the original dtype for quantized models as we cannot easily retrieve it\u001b[39;00m\n\u001b[0;32m   3394\u001b[0m     \u001b[38;5;66;03m# once the weights have been quantized\u001b[39;00m\n\u001b[0;32m   3395\u001b[0m     \u001b[38;5;66;03m# Note that once you have loaded a quantized model, you can't change its dtype so this will\u001b[39;00m\n\u001b[0;32m   3396\u001b[0m     \u001b[38;5;66;03m# remain a single source of truth\u001b[39;00m\n\u001b[0;32m   3397\u001b[0m     config\u001b[38;5;241m.\u001b[39m_pre_quantization_dtype \u001b[38;5;241m=\u001b[39m torch_dtype\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\quantizers\\base.py:166\u001b[0m, in \u001b[0;36mHfQuantizer.preprocess_model\u001b[1;34m(self, model, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m model\u001b[38;5;241m.\u001b[39mis_quantized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    165\u001b[0m model\u001b[38;5;241m.\u001b[39mquantization_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mquant_method\n\u001b[1;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_model_before_weight_loading(model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_4bit.py:256\u001b[0m, in \u001b[0;36mBnb4BitHfQuantizer._process_model_before_weight_loading\u001b[1;34m(self, model, device_map, keep_in_fp32_modules, **kwargs)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_model_before_weight_loading\u001b[39m(\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    251\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPreTrainedModel\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    255\u001b[0m ):\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_keys_to_not_convert, replace_with_bnb_linear\n\u001b[0;32m    258\u001b[0m     load_in_8bit_fp32_cpu_offload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantization_config\u001b[38;5;241m.\u001b[39mllm_int8_enable_fp32_cpu_offload\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# We keep some modules such as the lm_head in their original dtype for numerical stability reasons\u001b[39;00m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\utils\\import_utils.py:1380\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1378\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1380\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1381\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\JASONZ7\\.conda\\envs\\pytorch\\lib\\site-packages\\transformers\\utils\\import_utils.py:1392\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1393\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1394\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1395\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.bitsandbytes because of the following error (look up to see its traceback):\n\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForMaskedLM, BitsAndBytesConfig\n",
        "model_id = \"bert-base-chinese\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "base_model = AutoModelForMaskedLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    use_cache=False,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}